{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris: Bunch = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Iris Dataset into Training Set and Testing Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(iris['data'], iris['target'], random_state=0) # 75% training and 25% test\n",
    "\n",
    "iris_train = np.concatenate((X_train_iris, y_train_iris.reshape(-1, 1)), axis=1) # concatenate X_train_iris and y_train_iris\n",
    "iris_test = np.concatenate((X_test_iris, y_test_iris.reshape(-1, 1)), axis=1) # concatenate X_test_iris and y_test_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ionosphere = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Ionosphere Dataset into Training Set and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ionosphere, X_test_ionosphere = train_test_split(X_ionosphere, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbour Algorithm\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(data: list[tuple[int]], test: tuple[int], k: int) -> list[tuple[int]]:\n",
    "\t\"\"\"Finds the list of nearest neighbors relative to the test point. \n",
    "\n",
    "\tArgs:\n",
    "\t\tdata (list[tuple[int]]): list of points in the dataset\n",
    "\t\ttest (tuple[int]): test point to be compared to for distance\n",
    "\t\tk (int): number of nearest neighbors\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist: list of neighbors\n",
    "\t\"\"\"\n",
    "\tdistances: list[tuple] = []\n",
    "\tfor point in data: # for each point in the data set\n",
    "\t\tdistance = get_distance(test, point) # calculate the distance between the test point and the point in the data set\n",
    "\t\tdistances.append((point, distance)) # add tuple of point and distance to distances list\n",
    "\t\n",
    "\tsort_distances(distances)\n",
    "\t\n",
    "\tneighbors: list[tuple[int]] = [] # list of neighbors (currently empty)\n",
    "\tfor i in range(k): # for each neighbor\n",
    "\t\tneighbors.append(distances[i][0]) # add the point to the neighbors list\n",
    "\treturn neighbors\n",
    "\n",
    "def get_distance(test: tuple[int], point: tuple[int]) -> float:\n",
    "\t\"\"\"Calculates the distance between the test point and the point in the data set.\n",
    "\n",
    "\tArgs:\n",
    "\t\ttest (tuple[int]): test point to be compared to for distance\n",
    "\t\tpoint (tuple[int]): point in the data set to be compared to for distance\n",
    "\n",
    "\tReturns:\n",
    "\t\tfloat: distance between the test point and the point in the data set\n",
    "\t\"\"\"\n",
    "\tdistance = 0\n",
    "\tfor index, element in enumerate(test):\n",
    "\t\tdistance += (element - point[index])**2 \n",
    "\treturn distance**0.5\n",
    "\n",
    "def sort_distances(distances: list[tuple[int]]) -> list[tuple[int]]:\n",
    "\t\"\"\"Sorts the distances in ascending order.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdistances (list[tuple[int]]): list of distances\n",
    "\n",
    "\tReturns:\n",
    "\t\tlist[tuple[int]]: list of distances sorted in ascending order\n",
    "\t\"\"\"\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\treturn distances\n",
    "\n",
    "def get_prediction(neighbors: list) -> int:\n",
    "\t\"\"\"Gets the prediction based on the neighbors.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tneighbors (list): list of neighbors\n",
    "\n",
    "\tReturns:\n",
    "\t\tint: prediction\n",
    "\t\"\"\"\n",
    "\treturn neighbors[0][-1]\n",
    "\n",
    "def execute(data: list[tuple[int]], test: tuple[int], k: int) -> int:\n",
    "\t\"\"\"Executes the k-Nearest Neighbor algorithm on the given dataset, test and k.\n",
    "\n",
    "\tArgs:\n",
    "\t\tdata (list[tuple[int]]): list of points in the dataset\n",
    "\t\ttest (tuple[int]): test point to be compared to for distance\n",
    "\t\tk (int): number of nearest neighbors\n",
    "\n",
    "\tReturns:\n",
    "\t\tint: prediction\n",
    "\t\"\"\"\n",
    "\t# neighbors = get_neighbors(data, test, k)\n",
    "\t# prediction = get_prediction(get_neighbors(data, test, k))\n",
    "\treturn get_prediction(get_neighbors(data, test, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(execute(iris_train, iris_test[0], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9a317dd932dec76e8fdc8987ca60af4062f347c78c20ca5292cf26c8b2836138"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
